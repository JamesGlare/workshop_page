<html>
<head>
  <title>ML with New Compute Paradigms NeurIPS Workshop 2023</title>
  <meta name="description" content="ML with New Compute Paradigms NeurIPS Workshop 2023">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" type="text/css" href="styles.css">
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>ML with new Compute Paradigms (MLNCP)</h1>
    </div>
    <ul class="nav">
      <li><a href="#">Home</a></li>
      <li><a href="#call_for_papers">Call for Papers</a></li>
      <li><a href="#schedule">Schedule</a></li>
      <li><a href="#speakers">Speakers</a></li>
      <li><a href="#organisers">Organisers</a></li>
      <li><a href="#">Sponsors</a></li>
    </ul>
    <div class="content", id="abstract">
      <h2>Welcome to the MLNCP NeurIPS Workshop 2023 !</h2>
      <p>This workshop aims to bring together ML researchers with academic and industrial researchers building novel AI accelerators.
          The goal is to enable interaction between the two groups and kick-start a new feedback cycle between models and accelerators, that, is, to enable hardware-model co-design. 
          We welcomme algorithmic or model-innovations related to as well as results demonstrated on accelerators in the following categories: </p>
      <ul>
        <li>photonic or optical compute</li>
        <li>neuromorphic compute</li>
        <li>in-memory compute</li>
        <li>low-precision and edge-compute</li>
        <li>analog compute</li>
        <li>biologically-plausible machine-learning</li>
      </ul>
      <p>The workshop will be held on December 15th or 16th, 2023 as part of the NeurIPS conference in New Orleans, Louisiana.</p>
      <h2>Abstract</h2>
      <p>As GPU computing comes closer to a plateau in terms of efficiency and cost due
        to Moore' s law reaching its limit, there is a growing need to explore alternative
        computing paradigms, such as (opto-)analog, neuromorphic, and low-power computing. This NeurIPS workshop aims to unite researchers from machine learning
        and alternative computation fields to establish a new hardware-ML feedback loop.
        By co-designing models with specialized accelerators, we can leverage the benefits
        of increased throughput or lower per-flop power consumption. Novel devices hold
        the potential to further accelerate standard deep learning or even enable efficient inference and training of hitherto compute-constrained model classes. However, new
        compute paradigms typically present challenges such as intrinsic noise, restricted
        sets of compute operations, or limited bit-depth, and thus require model-hardware
        co-design. This workshop's goal is to foster cross-disciplinary collaboration to
        capitalize on the opportunities offered by emerging AI accelerators.</p>
    </div>
    <div class="content", id="call_for_papers">
        <h2>Call for Papers</h2>
        TBD
    </div>
    <div class="content", id="schedule">
        <h2>Schedule</h2>
        TBD
    </div>
    <div class="content", id="speakers">
        <h2>Speakers</h2>
        TBD
    </div>
    <div class="content", id="organisers">
        <h2>Organisers</h2>
      <p>The workshop is organised by the following people:</p>
      <ul>
        <li>Jannes Gladrow (Microsoft Research)</li>
        <li>Benjamin Scellier (Rain.ai)</li>
        <li>Eric Xing (Carneggie Mellon, Mohamed bin Zayed University of Artificial Intelligence) </li>
        <li>Babak Rahmani (Microsoft Research)</li>
        <li>Francesca Parmigiani (Microsoft Research)</li>
        <li>Paul R. Prucnal (Princeton University)</li>
        <li>Cheng Zhang (Microsoft Research)</li>
      </ul>
    </div>
    <div class="content", id="sponsors">
        <h2>Sponsors</h2>
        <ul>
            
        </ul>
    </div>
  </div>
</body>
</html>
