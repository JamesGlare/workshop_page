<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML with New Compute Paradigms Workshop at NeurIPS 2024</title>
    <meta name="description" content="ML with New Compute Paradigms NeurIPS Workshop 2024">
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@700&family=Roboto:wght@400&display=swap" rel="stylesheet">
     <!-- Add the favicon -->
     <link rel="icon" href="images/favicon.png" type="image/png">
     <link rel="apple-touch-icon" href="images/favicon.png">
     <meta property="og:image" content="images/favicon.png">
     <meta name="twitter:image" content="images/favicon.png">
  </head>
<body>
    <div class="top">
        <ul class="nav">
            <li><a href="#speakers">Speakers</a></li>
            <li><a href="#organisers">Organisers</a></li>
            <li><a href="#sponsors">Sponsors</a></li>
        </ul>
        <div class="header">
            <h1>ML with New Compute Paradigms (MLNCP) at NeurIPS 2024</h1>
        </div>
    </div>
    <div class="container">
        <div class="content" id="abstract">
            <h2>Welcome to the MLNCP Workshop at NeurIPS 2024!</h2>
            <p>The workshop will take place on the <b>14th or 15th December at NeurIPS 2024 in Vancouver, Canada</b>. The exact date and location will be announced soon.</p>

            <p>Digital computing is approaching fundamental limits and faces serious challenges in terms of scalability, performance, and sustainability. At the same time, generative AI is fuelling an explosion in compute demand. There is, thus, a growing need to explore non-traditional computing paradigms, such as (opto-)analog, neuromorphic hardware, and physical systems. Expanding on last year's successful NeurIPS workshop, which was the first of its kind in this community, we aim to bring together researchers from machine learning and alternative computation fields to establish new synergies between ML models and non-traditional hardware. Co-designing models with specialized hardware, a feature that has also been key to the synergy of digital chips like GPUs and deep learning, has the potential to offer a step change in the efficiency and sustainability of machine learning at scale. Beyond speeding up standard deep learning, new hardware may open the door for efficient inference and training of model classes that have been limited by compute resources, such as energy-based models and deep equilibrium models. So far, however, these hardware technologies have fallen short due to inherent noise, device mismatch, a limited set of compute operations, and reduced bit-depth. As a community, we need to develop new models and algorithms that can embrace and, in fact, exploit these characteristics. This workshop aims to encourage cross-disciplinary collaboration to exploit the opportunities offered by emerging AI accelerators both at training and at inference.</p>
        </div>
        <div class="call_for_papers">
            <h2>Call for Papers</h2>
            <ul>
                <li>Advances in machine-learning that benefit from compute paradigms beyond standard digital compute, for example analog, photonic, in-memory, neuromorphic, or quantum compute.</li>
                <li>Advances in machine learning methods that can handle challenges such as low bit precision, variability or noise induced by new hardware. Examples include inherently noise-robust models, algorithms to reduce errors in ML arithmetic, or ways to share and distribute models across unique analog hardware.</li>
                <li>Advances in machine-learning paradigms that facilitate training and/or inference on new hardware paradigms. This can be general or specific to, for example, generative models for modalities such as image or sequence data.</li>
                <li>Surveys and position papers for machine-learning with new compute paradigms.</li>
            </ul>
            <div class="submission-box">
                The submission deadline is <b>Sep 9th 2024 (Anywhere on Earth)</b>.<br>
                Formatting guideline: Please keep the submission length to 6 pages excluding references and use our LaTeX template <a href="./mlncp_2024.sty">mlncp_2024.sty</a>.<br>
                Please submit here <a href="https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/MLNCP">openreview.net/group?id=NeurIPS.cc/2024/Workshop/MLNCP</a> <br>
                This NeurIPS workshop is non-archival, meaning that submissions can be still be submitted to other venues after the workshop. Papers that have been submitted to the main conference, however, are not eligible for submission to the workshop.
            </div>
        </div>
        <div class="content" id="speakers">
            <h2>Speakers and Panellists</h2>
            <table class="speakers-table">
                <tr>
                    <td>
                        <img src="images/zico_kolter.jpg" alt="Zico Kolter">
                    </td>
                    <td>
                        <p><strong>Zico Kolter</strong></p>
                        <p>Prof. Zico Kolter is a professor at Carnegie Mellon University and Director of the Machine Learning Department as well as Chief Scientist of AI research at Bosch. His research spans several areas within machine learning and he is well-known for innovation in deep learning architectures as well as AI robustness and safety. He is a recipient of the DARPA Young Faculty Award, a Sloan Fellowship, and best paper awards at NeurIPS, ICML (honorable mention), AISTATS (test of time), IJCAI, KDD, and PESGM. Prof. Kolter recently joined the board of directors of OpenAI.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/dimitry_krotov.jpg" alt="Dimitry Krotov">
                    </td>
                    <td>
                        <p><strong>Dimitry Krotov</strong></p>
                        <p>Dmitry Krotov is a physicist working on neurobiologically inspired machine learning. He is a member of the research staff at the MIT-IBM Watson AI Lab and IBM Research in Cambridge, MA. Prior to this, he was a member of the Institute for Advanced Study in Princeton. His work mainly focuses on the theory of associative memory and energy-based neural architectures.

                        </p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/azalia_mirsoheini.jpg" alt="Azalia Mirsoheini">
                    </td>
                    <td>
                        <p><strong>Azalia Mirsoheini</strong></p>
                        <p>Azalia Mirhoseini is an assistant professor in the computer science department at Stanford University. Her research focuses on developing capable, reliable, and efficient AI systems. She has made significant contributions to decision-making problems in chip design, self-improving AI models, and scalable deep learning optimization.

                        Before joining Stanford, Azalia worked at industry AI labs, including Anthropic and Google Brain. At Google Brain, she co-founded the ML for Systems team, which focused on automating and optimizing computer systems and chip design. Azalia Mirhoseini's work has been recognized through several prestigious awards, including the MIT Technology Review's 35 Under 35 Award and the Best ECE Thesis Award at Rice University.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/mike_davies.jpg" alt="Mike Davies">
                    </td>
                    <td>
                        <p><strong>Mike Davies</strong></p>
                        <p> Mike Davies is the Director of Intel’s Neuromorphic Computing Lab, a position he has held since 2017. His work focuses on developing neuromorphic computing systems, that is, chips that are inspired by the principles of the human brain. These systems aim to create more efficient and powerful computing architectures by integrating memory and computation into a web of artificial neurons that exchange simple messages. Mike Davies joined Intel in 2011 following the acquisition of Fulcrum Microsystems, where he had been involved in IC development for 11 years.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/clara_wanjura.jpg" alt="Clara Wanjura">
                    </td>
                    <td>
                        <p><strong>Clara Wanjura</strong></p>
                        <p>Clara Wanjura is leading a Minerva Fast Track Group at the Max Planck Institute for the Science of Light since 2024. After her undergraduate studies at Ulm University, she moved to the University of Cambridge where she received her PhD in 2022. She became a postdoctoral researcher at the Max Planck Institute for the Science of Light in the group of Florian Marquardt in 2022 and received a Minerva Fast Track Fellowship in 2024.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/phillip_stanley_marbell.jpg" alt="Phillip Stanley-Marbell">
                    </td>
                    <td>
                        <p><strong>Phillip Stanley-Marbell</strong></p>
                        <p>Prof. Phillip Stanley-Marbell is leading the Physical Computation Laboratory at the University of Cambridge.  His research focuses on leveraging an understanding of the physical world to create more efficient computing system. Before joining Cambridge, his career included notable stints at Bell Labs, IBM Research in Zürich, and Apple in Cupertino. Furthermore, he has been a faculty fellow at the Alan Turing Institute in London since 2018.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/patrick_coles.png" alt="Patrick Coles">
                    </td>
                    <td>
                        <p><strong>Patrick Coles</strong></p>
                        <p> Patrick Coles is the Chief Scientist at Normal Computing, a deep tech AI startup known for pioneering thermodynamic computing. His work focuses on developing energy-efficient AI hardware systems that can unlock new capabilities, as well as decision-making under uncertainty. Before joining Normal Computing, Patrick Coles was the head of Quantum Computing at Los Alamos National Laboratory.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/ting_cao.jpg" alt="Ting Cao">
                    </td>
                    <td>
                        <p><strong>Ting Cao</strong></p>
                        <p> Ting Cao is a Principal Research Manager in the Heterogeneous Extreme Computing (HEX) group within the Systems and Networking research area at Microsoft Research. Ting received her Ph.D. from the Research School of Computer Science at the Australian National University. Her work has received a range of awards, such as 2012 ACM Research highlights, 2012 IEEE Micro Top Picks, 2021 ACM SIGMOBILE Research highlights, Best paper awards at various conferences as well as Huawei's Future star award.
                        </p>
                    </td>
                </tr>
            </table>
        </div>
        <div class="content" id="organisers">
            <h2>Organisers</h2>
            <p>The workshop is organised by the following people:</p>
            <ul>
                <li>Jannes Gladrow (Microsoft Research)</li>
                <li>Babak Rahmani (Microsoft Research)</li>
                <li>Julie Grollier (Thales/CNRS)</li>
                <li>Peter McMahon (Cornell)</li>
                <li>Ruqi Zhang (Purdue)</li>
                <li>Jack Kendall (rain.ai)</li>
            </ul>
        </div>
        <div class="content" id="sponsors">
            <h2>Sponsors</h2>
            <div class="sponsor-grid">
                <img src="images/aria_logo.png" alt="ARIA">
                <img src="images/rain.png" alt="Rain.ai">
                <img src="images/microsoft.jpg" alt="Microsoft">
            </div>
        </div>
        <div class="content" id="contact">
            <b>Contact:</b> MLwithNewCompute _at_ googlegroups.com
        </div>
    </div>
    <footer>
        <div class="footer-content">
            <p>2024 ML with New Compute Paradigms NeurIPS Workshop.</p>
            <p><a href="#top">Back to Top</a></p>
        </div>
    </footer>
</body>
</html>
